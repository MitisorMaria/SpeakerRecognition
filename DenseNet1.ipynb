{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1401,
     "status": "ok",
     "timestamp": 1593008857333,
     "user": {
      "displayName": "Maria Mitisor",
      "photoUrl": "",
      "userId": "15027573700781054713"
     },
     "user_tz": -180
    },
    "id": "Iz1IL-LsFkMo",
    "outputId": "3ebeb482-06c0-4269-fa23-f4a4128993f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 770,
     "status": "ok",
     "timestamp": 1592998307781,
     "user": {
      "displayName": "Maria Mitisor",
      "photoUrl": "",
      "userId": "15027573700781054713"
     },
     "user_tz": -180
    },
    "id": "2ueQE1_TFpM4",
    "outputId": "7c6f581e-f37d-4303-b4fe-4404023ea322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/Untitled folder/wav\n"
     ]
    }
   ],
   "source": [
    "cd /content/gdrive/My Drive/Untitled folder/wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importăm modulele necesare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7146,
     "status": "ok",
     "timestamp": 1592998317222,
     "user": {
      "displayName": "Maria Mitisor",
      "photoUrl": "",
      "userId": "15027573700781054713"
     },
     "user_tz": -180
    },
    "id": "cPoGrpzNahan",
    "outputId": "50d8bc45-dcf4-4a5c-f7bc-34314a0cc22f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import signal_processing, data_load, learn, evaluate, render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UkCE6NXdeZ2e"
   },
   "outputs": [],
   "source": [
    "num_rows = 128\n",
    "num_columns = 128\n",
    "num_channels = 3\n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 13\n",
    "num_speakers = 10\n",
    "num_seconds = 2.9\n",
    "fine_tune_at = 300\n",
    "base_lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 236069,
     "status": "ok",
     "timestamp": 1593009186299,
     "user": {
      "displayName": "Maria Mitisor",
      "photoUrl": "",
      "userId": "15027573700781054713"
     },
     "user_tz": -180
    },
    "id": "SRpzC9PxtFjA",
    "outputId": "5deb3fc0-2ccc-46da-8aa3-f53493de9163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  970  files\n"
     ]
    }
   ],
   "source": [
    "featuresdf = data_load.make_dataframe_class_no(num_speakers, './', num_rows, num_columns, num_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2166,
     "status": "ok",
     "timestamp": 1593009197616,
     "user": {
      "displayName": "Maria Mitisor",
      "photoUrl": "",
      "userId": "15027573700781054713"
     },
     "user_tz": -180
    },
    "id": "ttUQbv2rtFjD"
   },
   "outputs": [],
   "source": [
    "result_sets = data_load.make_train_test_sets(featuresdf, num_rows, num_columns, num_channels)\n",
    "num_labels = result_sets[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descărcăm modelul DenseNet 121:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8006,
     "status": "ok",
     "timestamp": 1593009206828,
     "user": {
      "displayName": "Maria Mitisor",
      "photoUrl": "",
      "userId": "15027573700781054713"
     },
     "user_tz": -180
    },
    "id": "yC2UFaTPtFjH",
    "outputId": "f33aea5d-f05f-42ad-a3f2-4c4fc33058f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  428\n",
      "Model: \"densenet121\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 134, 134, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 64, 64, 64)   9408        zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 64, 64, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 66, 66, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 32, 32, 64)   0           zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 32, 32, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 32, 32, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 32, 32, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 32, 32, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 32, 32, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 32, 32, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 32, 32, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 32, 32, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 32, 32, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 32, 32, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 32, 32, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 32, 32, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 32, 32, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 32, 32, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 32, 32, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 32, 32, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 32, 32, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 32, 32, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 32, 32, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 32, 32, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 32, 32, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 32, 32, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 32, 32, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 32, 32, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 32, 32, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 32, 32, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 32, 32, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 32, 32, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 32, 32, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 16, 16, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 16, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 16, 16, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 16, 16, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 16, 16, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 16, 16, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 16, 16, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 16, 16, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 16, 16, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 16, 16, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 16, 16, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 16, 16, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 16, 16, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 16, 16, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 16, 16, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 16, 16, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 16, 16, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 16, 16, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 16, 16, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 16, 16, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 16, 16, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 16, 16, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 16, 16, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 16, 16, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 16, 16, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 16, 16, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 16, 16, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 16, 16, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 16, 16, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 16, 16, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 16, 16, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 16, 16, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 16, 16, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 16, 16, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 16, 16, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 16, 16, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 16, 16, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 16, 16, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 16, 16, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 16, 16, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 16, 16, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 16, 16, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 16, 16, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 16, 16, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 16, 16, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 16, 16, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 16, 16, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 16, 16, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 16, 16, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 16, 16, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 16, 16, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 16, 16, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 8, 8, 256)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 8, 8, 256)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 128)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 8, 8, 288)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 8, 8, 288)    1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 8, 8, 288)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 128)    36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 128)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 8, 8, 320)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 8, 8, 320)    1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 8, 8, 320)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 128)    40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 128)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 8, 8, 352)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 8, 8, 352)    1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 8, 8, 352)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 128)    45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 128)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 8, 8, 384)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 8, 8, 384)    1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 8, 8, 384)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 128)    49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 128)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 8, 8, 416)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 8, 8, 416)    1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 8, 8, 416)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 128)    53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 128)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 8, 8, 448)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 8, 8, 448)    1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 8, 8, 448)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 8, 8, 128)    57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 8, 8, 128)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 8, 8, 480)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 8, 8, 480)    1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 8, 8, 480)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 8, 8, 128)    61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 8, 8, 128)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 8, 8, 512)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 8, 8, 512)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 8, 8, 128)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 8, 8, 544)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 8, 8, 544)    2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 8, 8, 544)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 8, 8, 128)    69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 8, 8, 576)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 8, 8, 576)    2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 8, 8, 576)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 8, 8, 128)    73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 8, 8, 608)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 8, 8, 608)    2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 8, 8, 608)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 8, 8, 128)    77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 8, 8, 640)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 8, 8, 640)    2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 8, 8, 640)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 8, 8, 128)    81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 8, 8, 672)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 8, 8, 672)    2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 8, 8, 672)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 8, 8, 128)    86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 8, 8, 704)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 8, 8, 704)    2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 8, 8, 704)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 8, 8, 128)    90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 8, 8, 736)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 8, 8, 736)    2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 8, 8, 736)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 8, 8, 128)    94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 8, 8, 768)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 8, 8, 768)    3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 8, 8, 768)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 8, 8, 128)    98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 8, 8, 800)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 8, 8, 800)    3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 8, 8, 800)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 8, 8, 128)    102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 8, 8, 832)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 8, 8, 832)    3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 8, 8, 832)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 8, 8, 128)    106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 8, 8, 864)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 8, 8, 864)    3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 8, 8, 864)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 8, 8, 128)    110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 8, 8, 896)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 8, 8, 896)    3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 8, 8, 896)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 8, 8, 128)    114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 8, 8, 928)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 8, 8, 928)    3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 8, 8, 928)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 8, 8, 128)    118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 8, 8, 960)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 8, 8, 960)    3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 8, 8, 960)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 8, 8, 128)    122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 8, 8, 992)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 8, 8, 992)    3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 8, 8, 992)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 8, 8, 128)    126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 8, 8, 1024)   0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 8, 8, 1024)   4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 8, 8, 1024)   0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 8, 8, 512)    524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 4, 4, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 4, 4, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 4, 4, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 4, 4, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 4, 4, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 4, 4, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 4, 4, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 4, 4, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 4, 4, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 4, 4, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 4, 4, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 4, 4, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 4, 4, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 4, 4, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 4, 4, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 4, 4, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 4, 4, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 4, 4, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 4, 4, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 4, 4, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 4, 4, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 4, 4, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 4, 4, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 4, 4, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 4, 4, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 4, 4, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 4, 4, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 4, 4, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 4, 4, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 4, 4, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 4, 4, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 4, 4, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 4, 4, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 4, 4, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 4, 4, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 4, 4, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 4, 4, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 4, 4, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 4, 4, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 4, 4, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 4, 4, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 4, 4, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 4, 4, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 4, 4, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 4, 4, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 4, 4, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 4, 4, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 4, 4, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 4, 4, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 4, 4, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 4, 4, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 4, 4, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 4, 4, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 4, 4, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 4, 4, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 4, 4, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 4, 4, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 4, 4, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 4, 4, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 4, 4, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 4, 4, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 4, 4, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 4, 4, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 4, 4, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 4, 4, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 4, 4, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 4, 4, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 4, 4, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 4, 4, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 7,037,504\n",
      "Trainable params: 2,889,408\n",
      "Non-trainable params: 4,148,096\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = learn.get_densenet(num_rows, num_columns, num_channels, num_labels, fine_tune_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5845,
     "status": "ok",
     "timestamp": 1593009216569,
     "user": {
      "displayName": "Maria Mitisor",
      "photoUrl": "",
      "userId": "15027573700781054713"
     },
     "user_tz": -180
    },
    "id": "h9B2mnJJtFjK",
    "outputId": "bc1faa04-1165-4aac-ee16-233cd443453d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 1024)              7037504   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 7,047,754\n",
      "Trainable params: 2,899,658\n",
      "Non-trainable params: 4,148,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = learn.build_model_densenet(base_model, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 670,
     "status": "ok",
     "timestamp": 1593009218882,
     "user": {
      "displayName": "Maria Mitisor",
      "photoUrl": "",
      "userId": "15027573700781054713"
     },
     "user_tz": -180
    },
    "id": "m4M6d6pLtFjO"
   },
   "outputs": [],
   "source": [
    "learn.compile_model_pretrained_net(model, base_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38858,
     "status": "ok",
     "timestamp": 1593009261440,
     "user": {
      "displayName": "Maria Mitisor",
      "photoUrl": "",
      "userId": "15027573700781054713"
     },
     "user_tz": -180
    },
    "id": "TRtT-4xMtFjV",
    "outputId": "f554db74-709a-4198-b6fc-baf63770d353"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 1024)              7037504   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 7,047,754\n",
      "Trainable params: 2,899,658\n",
      "Non-trainable params: 4,148,096\n",
      "_________________________________________________________________\n",
      "25/25 [==============================] - 33s 1s/step - loss: 20.5028 - accuracy: 0.0915\n",
      "Pre-training accuracy: 9.1495%\n"
     ]
    }
   ],
   "source": [
    "evaluate.evaluate_before_training(model, result_sets[0], result_sets[2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antrenăm modelul:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5879971,
     "status": "ok",
     "timestamp": 1593015154036,
     "user": {
      "displayName": "Maria Mitisor",
      "photoUrl": "",
      "userId": "15027573700781054713"
     },
     "user_tz": -180
    },
    "id": "Kk4Y_NRptFjZ",
    "outputId": "f11ea233-1e6c-48e3-e616-2870be4005c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 9.6930 - accuracy: 0.3827\n",
      "Epoch 00001: val_loss improved from inf to 2.12604, saving model to saved_models/weights.best.DenseNet1.hdf5\n",
      "60/60 [==============================] - 60s 993ms/step - loss: 9.6930 - accuracy: 0.3827 - val_loss: 2.1260 - val_accuracy: 0.2371\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 6.3698 - accuracy: 0.5851\n",
      "Epoch 00002: val_loss improved from 2.12604 to 1.86924, saving model to saved_models/weights.best.DenseNet1.hdf5\n",
      "60/60 [==============================] - 59s 981ms/step - loss: 6.3698 - accuracy: 0.5851 - val_loss: 1.8692 - val_accuracy: 0.2835\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 5.0052 - accuracy: 0.6765\n",
      "Epoch 00003: val_loss improved from 1.86924 to 1.39859, saving model to saved_models/weights.best.DenseNet1.hdf5\n",
      "60/60 [==============================] - 59s 988ms/step - loss: 5.0052 - accuracy: 0.6765 - val_loss: 1.3986 - val_accuracy: 0.5103\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 4.1475 - accuracy: 0.7423\n",
      "Epoch 00004: val_loss improved from 1.39859 to 1.33790, saving model to saved_models/weights.best.DenseNet1.hdf5\n",
      "60/60 [==============================] - 60s 993ms/step - loss: 4.1475 - accuracy: 0.7423 - val_loss: 1.3379 - val_accuracy: 0.4742\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 3.3587 - accuracy: 0.8003\n",
      "Epoch 00005: val_loss improved from 1.33790 to 0.99377, saving model to saved_models/weights.best.DenseNet1.hdf5\n",
      "60/60 [==============================] - 60s 994ms/step - loss: 3.3587 - accuracy: 0.8003 - val_loss: 0.9938 - val_accuracy: 0.7113\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.7402 - accuracy: 0.8144\n",
      "Epoch 00006: val_loss did not improve from 0.99377\n",
      "60/60 [==============================] - 58s 966ms/step - loss: 2.7402 - accuracy: 0.8144 - val_loss: 1.0146 - val_accuracy: 0.6598\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.4381 - accuracy: 0.8351\n",
      "Epoch 00007: val_loss improved from 0.99377 to 0.76821, saving model to saved_models/weights.best.DenseNet1.hdf5\n",
      "60/60 [==============================] - 58s 975ms/step - loss: 2.4381 - accuracy: 0.8351 - val_loss: 0.7682 - val_accuracy: 0.7216\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.0056 - accuracy: 0.8776\n",
      "Epoch 00008: val_loss did not improve from 0.76821\n",
      "60/60 [==============================] - 58s 966ms/step - loss: 2.0056 - accuracy: 0.8776 - val_loss: 1.0024 - val_accuracy: 0.7165\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.7416 - accuracy: 0.8853\n",
      "Epoch 00009: val_loss did not improve from 0.76821\n",
      "60/60 [==============================] - 58s 961ms/step - loss: 1.7416 - accuracy: 0.8853 - val_loss: 1.0147 - val_accuracy: 0.6907\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.6339 - accuracy: 0.8956\n",
      "Epoch 00010: val_loss did not improve from 0.76821\n",
      "60/60 [==============================] - 61s 1s/step - loss: 1.6339 - accuracy: 0.8956 - val_loss: 1.0358 - val_accuracy: 0.7010\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.2461 - accuracy: 0.9253\n",
      "Epoch 00011: val_loss did not improve from 0.76821\n",
      "60/60 [==============================] - 58s 963ms/step - loss: 1.2461 - accuracy: 0.9253 - val_loss: 0.9475 - val_accuracy: 0.7165\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9555 - accuracy: 0.9485\n",
      "Epoch 00012: val_loss improved from 0.76821 to 0.75350, saving model to saved_models/weights.best.DenseNet1.hdf5\n",
      "60/60 [==============================] - 60s 1s/step - loss: 0.9555 - accuracy: 0.9485 - val_loss: 0.7535 - val_accuracy: 0.7526\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.0940 - accuracy: 0.9317\n",
      "Epoch 00013: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 962ms/step - loss: 1.0940 - accuracy: 0.9317 - val_loss: 1.0435 - val_accuracy: 0.7113\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9124 - accuracy: 0.9536\n",
      "Epoch 00014: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 965ms/step - loss: 0.9124 - accuracy: 0.9536 - val_loss: 0.9535 - val_accuracy: 0.7216\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7454 - accuracy: 0.9588\n",
      "Epoch 00015: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 973ms/step - loss: 0.7454 - accuracy: 0.9588 - val_loss: 0.9272 - val_accuracy: 0.7165\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7609 - accuracy: 0.9523\n",
      "Epoch 00016: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 963ms/step - loss: 0.7609 - accuracy: 0.9523 - val_loss: 0.9384 - val_accuracy: 0.7268\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7151 - accuracy: 0.9639\n",
      "Epoch 00017: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 61s 1s/step - loss: 0.7151 - accuracy: 0.9639 - val_loss: 1.0680 - val_accuracy: 0.7371\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6171 - accuracy: 0.9665\n",
      "Epoch 00018: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 59s 984ms/step - loss: 0.6171 - accuracy: 0.9665 - val_loss: 0.9542 - val_accuracy: 0.6907\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6271 - accuracy: 0.9678\n",
      "Epoch 00019: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 967ms/step - loss: 0.6271 - accuracy: 0.9678 - val_loss: 1.1041 - val_accuracy: 0.7268\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.9601\n",
      "Epoch 00020: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 961ms/step - loss: 0.6914 - accuracy: 0.9601 - val_loss: 0.8044 - val_accuracy: 0.7320\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7056 - accuracy: 0.9691\n",
      "Epoch 00021: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 60s 1s/step - loss: 0.7056 - accuracy: 0.9691 - val_loss: 0.9377 - val_accuracy: 0.7216\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5327 - accuracy: 0.9691\n",
      "Epoch 00022: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 59s 979ms/step - loss: 0.5327 - accuracy: 0.9691 - val_loss: 0.8753 - val_accuracy: 0.7371\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6538 - accuracy: 0.9536\n",
      "Epoch 00023: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 59s 992ms/step - loss: 0.6538 - accuracy: 0.9536 - val_loss: 1.0156 - val_accuracy: 0.6804\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4550 - accuracy: 0.9768\n",
      "Epoch 00024: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 59s 979ms/step - loss: 0.4550 - accuracy: 0.9768 - val_loss: 0.9970 - val_accuracy: 0.7680\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4185 - accuracy: 0.9807\n",
      "Epoch 00025: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 59s 985ms/step - loss: 0.4185 - accuracy: 0.9807 - val_loss: 1.2029 - val_accuracy: 0.7062\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.9768\n",
      "Epoch 00026: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 59s 984ms/step - loss: 0.3787 - accuracy: 0.9768 - val_loss: 0.8526 - val_accuracy: 0.7371\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3227 - accuracy: 0.9858\n",
      "Epoch 00027: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 59s 977ms/step - loss: 0.3227 - accuracy: 0.9858 - val_loss: 0.9698 - val_accuracy: 0.7320\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3979 - accuracy: 0.9691\n",
      "Epoch 00028: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 59s 982ms/step - loss: 0.3979 - accuracy: 0.9691 - val_loss: 1.0932 - val_accuracy: 0.7474\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.9691\n",
      "Epoch 00029: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 59s 988ms/step - loss: 0.4381 - accuracy: 0.9691 - val_loss: 0.8375 - val_accuracy: 0.7577\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.9820\n",
      "Epoch 00030: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 59s 987ms/step - loss: 0.2818 - accuracy: 0.9820 - val_loss: 0.7621 - val_accuracy: 0.7784\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.9742\n",
      "Epoch 00031: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 62s 1s/step - loss: 0.4367 - accuracy: 0.9742 - val_loss: 1.2890 - val_accuracy: 0.6856\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3058 - accuracy: 0.9858\n",
      "Epoch 00032: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 57s 950ms/step - loss: 0.3058 - accuracy: 0.9858 - val_loss: 1.0295 - val_accuracy: 0.7216\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3274 - accuracy: 0.9807\n",
      "Epoch 00033: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 57s 947ms/step - loss: 0.3274 - accuracy: 0.9807 - val_loss: 1.0136 - val_accuracy: 0.7629\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.9858\n",
      "Epoch 00034: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 965ms/step - loss: 0.2755 - accuracy: 0.9858 - val_loss: 0.8046 - val_accuracy: 0.7938\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.9807\n",
      "Epoch 00035: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 959ms/step - loss: 0.3482 - accuracy: 0.9807 - val_loss: 0.9371 - val_accuracy: 0.7320\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.9871\n",
      "Epoch 00036: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 964ms/step - loss: 0.2471 - accuracy: 0.9871 - val_loss: 0.7968 - val_accuracy: 0.7784\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.9845\n",
      "Epoch 00037: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 57s 952ms/step - loss: 0.2963 - accuracy: 0.9845 - val_loss: 0.7850 - val_accuracy: 0.7732\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.9807\n",
      "Epoch 00038: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 961ms/step - loss: 0.2855 - accuracy: 0.9807 - val_loss: 0.8767 - val_accuracy: 0.8093\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9923\n",
      "Epoch 00039: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 57s 953ms/step - loss: 0.1616 - accuracy: 0.9923 - val_loss: 1.0602 - val_accuracy: 0.7320\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3274 - accuracy: 0.9794\n",
      "Epoch 00040: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 57s 945ms/step - loss: 0.3274 - accuracy: 0.9794 - val_loss: 1.0705 - val_accuracy: 0.6649\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.9858\n",
      "Epoch 00041: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 60s 994ms/step - loss: 0.2035 - accuracy: 0.9858 - val_loss: 0.8012 - val_accuracy: 0.7784\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.9807\n",
      "Epoch 00042: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 59s 986ms/step - loss: 0.3287 - accuracy: 0.9807 - val_loss: 0.8754 - val_accuracy: 0.8144\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.9858\n",
      "Epoch 00043: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 57s 958ms/step - loss: 0.2317 - accuracy: 0.9858 - val_loss: 1.2911 - val_accuracy: 0.6753\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.9910\n",
      "Epoch 00044: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 961ms/step - loss: 0.1827 - accuracy: 0.9910 - val_loss: 1.3112 - val_accuracy: 0.7268\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.9858\n",
      "Epoch 00045: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 969ms/step - loss: 0.2218 - accuracy: 0.9858 - val_loss: 0.9148 - val_accuracy: 0.7577\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2009 - accuracy: 0.9832\n",
      "Epoch 00046: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 963ms/step - loss: 0.2009 - accuracy: 0.9832 - val_loss: 1.0757 - val_accuracy: 0.7629\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2842 - accuracy: 0.9884\n",
      "Epoch 00047: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 966ms/step - loss: 0.2842 - accuracy: 0.9884 - val_loss: 1.0940 - val_accuracy: 0.7371\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1917 - accuracy: 0.9871\n",
      "Epoch 00048: val_loss did not improve from 0.75350\n",
      "60/60 [==============================] - 58s 959ms/step - loss: 0.1917 - accuracy: 0.9871 - val_loss: 0.7970 - val_accuracy: 0.8041\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1882 - accuracy: 0.9884\n",
      "Epoch 00049: val_loss improved from 0.75350 to 0.63405, saving model to saved_models/weights.best.DenseNet1.hdf5\n",
      "60/60 [==============================] - 59s 988ms/step - loss: 0.1882 - accuracy: 0.9884 - val_loss: 0.6341 - val_accuracy: 0.8299\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.9884\n",
      "Epoch 00050: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 947ms/step - loss: 0.1785 - accuracy: 0.9884 - val_loss: 0.9022 - val_accuracy: 0.7577\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9936\n",
      "Epoch 00051: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 58s 961ms/step - loss: 0.1178 - accuracy: 0.9936 - val_loss: 0.9487 - val_accuracy: 0.7835\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1965 - accuracy: 0.9884\n",
      "Epoch 00052: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 60s 1s/step - loss: 0.1965 - accuracy: 0.9884 - val_loss: 1.4751 - val_accuracy: 0.7577\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.9948\n",
      "Epoch 00053: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 948ms/step - loss: 0.1945 - accuracy: 0.9948 - val_loss: 0.8765 - val_accuracy: 0.7938\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9948\n",
      "Epoch 00054: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 949ms/step - loss: 0.1184 - accuracy: 0.9948 - val_loss: 1.2311 - val_accuracy: 0.7216\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2750 - accuracy: 0.9832\n",
      "Epoch 00055: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 950ms/step - loss: 0.2750 - accuracy: 0.9832 - val_loss: 0.7233 - val_accuracy: 0.7990\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9923\n",
      "Epoch 00056: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 58s 961ms/step - loss: 0.1127 - accuracy: 0.9923 - val_loss: 0.8512 - val_accuracy: 0.8041\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2127 - accuracy: 0.9897\n",
      "Epoch 00057: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 58s 964ms/step - loss: 0.2127 - accuracy: 0.9897 - val_loss: 1.1152 - val_accuracy: 0.7474\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9948\n",
      "Epoch 00058: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 58s 963ms/step - loss: 0.1243 - accuracy: 0.9948 - val_loss: 1.1505 - val_accuracy: 0.6856\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.9858\n",
      "Epoch 00059: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 952ms/step - loss: 0.1554 - accuracy: 0.9858 - val_loss: 0.9420 - val_accuracy: 0.7887\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2254 - accuracy: 0.9845\n",
      "Epoch 00060: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 948ms/step - loss: 0.2254 - accuracy: 0.9845 - val_loss: 0.8713 - val_accuracy: 0.7835\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.9871\n",
      "Epoch 00061: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 952ms/step - loss: 0.2195 - accuracy: 0.9871 - val_loss: 0.9872 - val_accuracy: 0.7680\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.9910\n",
      "Epoch 00062: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 59s 991ms/step - loss: 0.1247 - accuracy: 0.9910 - val_loss: 0.9613 - val_accuracy: 0.7526\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1631 - accuracy: 0.9910\n",
      "Epoch 00063: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 956ms/step - loss: 0.1631 - accuracy: 0.9910 - val_loss: 1.0065 - val_accuracy: 0.7629\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.9845\n",
      "Epoch 00064: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 956ms/step - loss: 0.2133 - accuracy: 0.9845 - val_loss: 0.8083 - val_accuracy: 0.7629\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1227 - accuracy: 0.9910\n",
      "Epoch 00065: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 954ms/step - loss: 0.1227 - accuracy: 0.9910 - val_loss: 0.9333 - val_accuracy: 0.7526\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1135 - accuracy: 0.9936\n",
      "Epoch 00066: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 956ms/step - loss: 0.1135 - accuracy: 0.9936 - val_loss: 0.7719 - val_accuracy: 0.7938\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9910\n",
      "Epoch 00067: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 950ms/step - loss: 0.1485 - accuracy: 0.9910 - val_loss: 2.6262 - val_accuracy: 0.6443\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1810 - accuracy: 0.9884\n",
      "Epoch 00068: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 949ms/step - loss: 0.1810 - accuracy: 0.9884 - val_loss: 0.9794 - val_accuracy: 0.7474\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.9923\n",
      "Epoch 00069: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 958ms/step - loss: 0.0984 - accuracy: 0.9923 - val_loss: 0.9550 - val_accuracy: 0.7835\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9936\n",
      "Epoch 00070: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 58s 959ms/step - loss: 0.1405 - accuracy: 0.9936 - val_loss: 0.8205 - val_accuracy: 0.7784\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9871\n",
      "Epoch 00071: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 58s 964ms/step - loss: 0.1561 - accuracy: 0.9871 - val_loss: 0.9059 - val_accuracy: 0.7835\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9923\n",
      "Epoch 00072: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 60s 1s/step - loss: 0.1052 - accuracy: 0.9923 - val_loss: 1.5453 - val_accuracy: 0.7268\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1436 - accuracy: 0.9910\n",
      "Epoch 00073: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 956ms/step - loss: 0.1436 - accuracy: 0.9910 - val_loss: 1.1271 - val_accuracy: 0.7577\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1459 - accuracy: 0.9858\n",
      "Epoch 00074: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 58s 959ms/step - loss: 0.1459 - accuracy: 0.9858 - val_loss: 1.0154 - val_accuracy: 0.8093\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.9936\n",
      "Epoch 00075: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 945ms/step - loss: 0.1224 - accuracy: 0.9936 - val_loss: 0.9135 - val_accuracy: 0.7629\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9936\n",
      "Epoch 00076: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 953ms/step - loss: 0.0790 - accuracy: 0.9936 - val_loss: 1.1202 - val_accuracy: 0.7680\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.9948\n",
      "Epoch 00077: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 951ms/step - loss: 0.1115 - accuracy: 0.9948 - val_loss: 0.8636 - val_accuracy: 0.7990\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9910\n",
      "Epoch 00078: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 938ms/step - loss: 0.1187 - accuracy: 0.9910 - val_loss: 1.1119 - val_accuracy: 0.7268\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9948\n",
      "Epoch 00079: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 941ms/step - loss: 0.1175 - accuracy: 0.9948 - val_loss: 0.6783 - val_accuracy: 0.8041\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.9832\n",
      "Epoch 00080: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 942ms/step - loss: 0.2368 - accuracy: 0.9832 - val_loss: 1.0483 - val_accuracy: 0.7577\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9961\n",
      "Epoch 00081: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 950ms/step - loss: 0.0676 - accuracy: 0.9961 - val_loss: 0.9260 - val_accuracy: 0.7835\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.9884\n",
      "Epoch 00082: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 954ms/step - loss: 0.1394 - accuracy: 0.9884 - val_loss: 0.9495 - val_accuracy: 0.7938\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9961\n",
      "Epoch 00083: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 59s 980ms/step - loss: 0.0712 - accuracy: 0.9961 - val_loss: 1.2658 - val_accuracy: 0.7010\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9884\n",
      "Epoch 00084: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 933ms/step - loss: 0.1296 - accuracy: 0.9884 - val_loss: 0.8737 - val_accuracy: 0.7887\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 00085: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 942ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.2784 - val_accuracy: 0.8093\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.9897\n",
      "Epoch 00086: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 930ms/step - loss: 0.1654 - accuracy: 0.9897 - val_loss: 1.3577 - val_accuracy: 0.7784\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.9923\n",
      "Epoch 00087: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 937ms/step - loss: 0.1179 - accuracy: 0.9923 - val_loss: 1.1487 - val_accuracy: 0.7887\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9961\n",
      "Epoch 00088: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 931ms/step - loss: 0.0875 - accuracy: 0.9961 - val_loss: 1.0654 - val_accuracy: 0.7629\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9936\n",
      "Epoch 00089: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 940ms/step - loss: 0.0924 - accuracy: 0.9936 - val_loss: 0.8379 - val_accuracy: 0.8144\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.9897\n",
      "Epoch 00090: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 954ms/step - loss: 0.1611 - accuracy: 0.9897 - val_loss: 1.0410 - val_accuracy: 0.8041\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.9948\n",
      "Epoch 00091: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 940ms/step - loss: 0.1352 - accuracy: 0.9948 - val_loss: 0.8545 - val_accuracy: 0.7835\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9936\n",
      "Epoch 00092: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 944ms/step - loss: 0.0962 - accuracy: 0.9936 - val_loss: 1.6058 - val_accuracy: 0.7577\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1453 - accuracy: 0.9923\n",
      "Epoch 00093: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 57s 944ms/step - loss: 0.1453 - accuracy: 0.9923 - val_loss: 1.4689 - val_accuracy: 0.7320\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1225 - accuracy: 0.9923\n",
      "Epoch 00094: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 59s 976ms/step - loss: 0.1225 - accuracy: 0.9923 - val_loss: 1.0117 - val_accuracy: 0.7526\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9910\n",
      "Epoch 00095: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 936ms/step - loss: 0.1027 - accuracy: 0.9910 - val_loss: 0.9021 - val_accuracy: 0.7938\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9936\n",
      "Epoch 00096: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 934ms/step - loss: 0.1094 - accuracy: 0.9936 - val_loss: 1.3716 - val_accuracy: 0.7784\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9948\n",
      "Epoch 00097: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 932ms/step - loss: 0.1325 - accuracy: 0.9948 - val_loss: 0.8903 - val_accuracy: 0.7784\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9936\n",
      "Epoch 00098: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 937ms/step - loss: 0.0741 - accuracy: 0.9936 - val_loss: 1.1075 - val_accuracy: 0.7268\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9974\n",
      "Epoch 00099: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 933ms/step - loss: 0.0514 - accuracy: 0.9974 - val_loss: 0.9939 - val_accuracy: 0.7680\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9948\n",
      "Epoch 00100: val_loss did not improve from 0.63405\n",
      "60/60 [==============================] - 56s 930ms/step - loss: 0.0956 - accuracy: 0.9948 - val_loss: 1.0384 - val_accuracy: 0.7938\n",
      "Training completed in time:  1:37:59.271233\n"
     ]
    }
   ],
   "source": [
    "class_weight = learn.calculate_class_weight(featuresdf)\n",
    "history = learn.train_model_class_weights(model, result_sets, num_epochs, num_batch_size, 'DenseNet1', 'default', 'DenseNet1', class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47657,
     "status": "ok",
     "timestamp": 1593015986861,
     "user": {
      "displayName": "Maria Mitisor",
      "photoUrl": "",
      "userId": "15027573700781054713"
     },
     "user_tz": -180
    },
    "id": "I2p-lIKFtFjc",
    "outputId": "ed1f3507-4f57-455b-f822-69e3b5ed3012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.8298969268798828\n"
     ]
    }
   ],
   "source": [
    "evaluate.evaluate_model(model, 'DenseNet1', result_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11475,
     "status": "ok",
     "timestamp": 1593016037186,
     "user": {
      "displayName": "Maria Mitisor",
      "photoUrl": "",
      "userId": "15027573700781054713"
     },
     "user_tz": -180
    },
    "id": "hFZwgnSytFjf",
    "outputId": "0f93f0b0-c776-49c7-c0ab-7cb290867088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82        16\n",
      "           1       0.82      1.00      0.90        18\n",
      "           2       0.97      0.88      0.93        43\n",
      "           3       0.64      0.80      0.71        20\n",
      "           4       0.64      0.54      0.58        13\n",
      "           5       0.94      0.97      0.95        30\n",
      "           6       0.71      0.86      0.77        14\n",
      "           7       1.00      0.94      0.97        16\n",
      "           8       1.00      0.58      0.74        12\n",
      "           9       0.56      0.42      0.48        12\n",
      "\n",
      "    accuracy                           0.83       194\n",
      "   macro avg       0.80      0.79      0.79       194\n",
      "weighted avg       0.84      0.83      0.83       194\n",
      "\n",
      "Confusion matrix: \n",
      "[[14  0  0  1  0  0  0  0  0  1]\n",
      " [ 0 18  0  0  0  0  0  0  0  0]\n",
      " [ 1  1 38  1  1  0  1  0  0  0]\n",
      " [ 0  1  0 16  2  0  1  0  0  0]\n",
      " [ 2  0  0  1  7  0  1  0  0  2]\n",
      " [ 0  0  0  0  0 29  1  0  0  0]\n",
      " [ 0  0  0  1  1  0 12  0  0  0]\n",
      " [ 0  0  0  0  0  0  1 15  0  0]\n",
      " [ 0  1  0  2  0  1  0  0  7  1]\n",
      " [ 1  1  1  3  0  1  0  0  0  5]]\n"
     ]
    }
   ],
   "source": [
    "evaluate.display_metrics(model, 'DenseNet1', result_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1178,
     "status": "ok",
     "timestamp": 1593016050414,
     "user": {
      "displayName": "Maria Mitisor",
      "photoUrl": "",
      "userId": "15027573700781054713"
     },
     "user_tz": -180
    },
    "id": "aQL9Ie5StFji",
    "outputId": "7d65a756-c453-4d2b-a89c-9b6b704a685f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate.plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DenseNet1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
