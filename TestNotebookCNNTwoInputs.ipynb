{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import evaluate, learn, signal_processing, data_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_mfcc = 45\n",
    "num_rows_mel = 32\n",
    "num_cols_mfcc= 130\n",
    "num_cols_mel = 110\n",
    "num_channels = 1\n",
    "\n",
    "hop_length = 1024 \n",
    "n_fft = 2048\n",
    "\n",
    "fine_tune_at = 300\n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 13\n",
    "num_speakers = 10\n",
    "num_seconds = 3.0\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learn.create_model_with_two_inputs(num_labels, num_rows_mfcc, num_cols_mfcc, num_rows_mel, num_cols_mel, num_channels)\n",
    "#base_model = learn.get_densenet(num_rows, num_columns, num_channels, num_labels, fine_tune_at)\n",
    "#model = learn.build_model_densenet(base_model, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"saved_models/weights.best.CNNTwoInputs.hdf5\")\n",
    "#model.load_weights(\"saved_models/weights.best.DenseNet1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "y = np.array(['A.J._Buckley', 'A.R._Rahman', 'Aamir_Khan', 'Aaron_Tveit', 'Aaron_Yoo', 'Abbie_Cornish', 'Abigail_Breslin', \n",
    "             'Abigail_Spencer', 'Adam_Beach', 'Adam_Brody'])\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "def print_prediction(file_name, model, num_rows_mfcc, num_cols_mfcc, num_rows_mel, num_cols_mel, n_fft, hop_length, num_channels, num_seconds):\n",
    "    prediction_feature_mfcc = signal_processing.extract_features_mfcc_seconds(file_name, num_rows_mfcc, num_cols_mfcc, num_seconds)\n",
    "    prediction_feature_mfcc = prediction_feature_mfcc.reshape(1, num_rows_mfcc, num_cols_mfcc, num_channels)\n",
    "    \n",
    "    prediction_feature_melspec = signal_processing.extract_features_melspectrogram(file_name, n_fft, num_rows_mel, hop_length, num_cols_mel, num_seconds)\n",
    "    prediction_feature_melspec = prediction_feature_melspec.reshape(1, num_rows_mel, num_cols_mel, num_channels)\n",
    "\n",
    "    predicted_vector = model.predict([prediction_feature_mfcc, prediction_feature_melspec])\n",
    "    predicted_class = np.argmax(predicted_vector)\n",
    "    print(predicted_vector)\n",
    "    print(data_load.nr_to_class_label(predicted_class))\n",
    "    \n",
    "    #predicted_class = le.inverse_transform(predicted_vector) \n",
    "    #print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    #predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    #predicted_proba = predicted_proba_vector[0]\n",
    "    #for i in range(len(predicted_proba)): \n",
    "     #   category = le.inverse_transform(np.array([i]))\n",
    "      #  print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.3926765e-03 1.6836150e-04 3.5418525e-02 2.0737862e-02 3.9250677e-04\n",
      "  8.5177487e-01 4.3863552e-03 8.2506344e-02 1.8422371e-04 3.8272043e-05]]\n",
      "Abbie_Cornish\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./test_clips/abbie_cornish/1/test_abbie_cornish3.wav', model, num_rows_mfcc, num_cols_mfcc, num_rows_mel, num_cols_mel, n_fft, hop_length, num_channels, num_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0283561e-03 2.7266439e-02 7.0650053e-01 9.1868290e-04 2.5917363e-01\n",
      "  2.1554786e-03 9.9037417e-05 3.6930436e-05 2.2212332e-03 5.9968064e-04]]\n",
      "Aamir_Khan\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./test_clips/aaron_tveit/1/test_aaron_tveit2.wav', model, num_rows_mfcc, num_cols_mfcc, num_rows_mel, num_cols_mel, n_fft, hop_length, num_channels, num_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.7828233e-05 4.9788057e-05 4.1754353e-03 2.6208572e-02 9.0214817e-05\n",
      "  9.1178203e-03 6.8890081e-06 9.5944303e-01 8.7995752e-04 4.9475051e-07]]\n",
      "Abigail_Spencer\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./test_clips/aamir_khan/1/test_aamir_khan5.wav', model, num_rows_mfcc, num_cols_mfcc, num_rows_mel, num_cols_mel, n_fft, hop_length, num_channels, num_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.8871030e-03 1.4605089e-04 2.1326866e-02 1.0893114e-03 3.8920230e-01\n",
      "  3.3844283e-01 8.4407383e-04 4.0040337e-04 2.2281861e-01 1.5842497e-02]]\n",
      "Aaron_Yoo\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./test_clips/aaron_yoo/1/test_aaron_yoo12.wav', model, num_rows_mfcc, num_cols_mfcc, num_rows_mel, num_cols_mel, n_fft, hop_length, num_channels, num_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.9649214e-04 8.1015260e-06 3.2579577e-01 2.7758157e-04 1.3672869e-01\n",
      "  4.3170784e-02 4.1078938e-06 3.0710572e-02 4.6232370e-01 4.8433157e-04]]\n",
      "Adam_Beach\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./test_clips/abigail_breslin/2/test_abigail_breslin4.wav', model, num_rows_mfcc, num_cols_mfcc, num_rows_mel, num_cols_mel, n_fft, hop_length, num_channels, num_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.5020563e-08 2.4975763e-10 2.2882580e-04 2.3108990e-01 2.7876236e-05\n",
      "  6.5978810e-02 4.2043239e-04 6.9974607e-01 2.2232824e-03 2.8468543e-04]]\n",
      "Abigail_Spencer\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./test_clips/abigail_spencer/1/test_abigail_spencer9.wav', model, num_rows_mfcc, num_cols_mfcc, num_rows_mel, num_cols_mel, n_fft, hop_length, num_channels, num_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.77483093e-03 4.07867810e-06 4.28875001e-06 5.38713466e-05\n",
      "  5.18199522e-04 7.33704015e-04 2.15916543e-06 2.50164285e-05\n",
      "  9.92781103e-01 1.02752194e-04]]\n",
      "Adam_Beach\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./test_clips/adam_beach/5/test_adam_beach12.wav', model, num_rows_mfcc, num_cols_mfcc, num_rows_mel, num_cols_mel, n_fft, hop_length, num_channels, num_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0305922e-05 6.8516165e-05 2.7134130e-02 2.8818769e-02 4.2360169e-03\n",
      "  6.0420427e-03 8.2822656e-03 5.9906826e-03 1.4697686e-04 9.1927028e-01]]\n",
      "Adam_Brody\n"
     ]
    }
   ],
   "source": [
    "print_prediction('./test_clips/adam_brody/1/test_adam_brody3.wav', model, num_rows_mfcc, num_cols_mfcc, num_rows_mel, num_cols_mel, n_fft, hop_length, num_channels, num_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
